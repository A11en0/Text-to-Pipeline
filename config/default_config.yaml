# Default System Configuration File
# You can copy and modify this file to create custom configurations

# LLM Configuration
llm_config:
  default_model: "gpt-4o-mini"  # Default model name
  models:
    gpt-4o-mini:  # OpenAI model configuration
      api_key: ""  # API Key
      api_base: "https://api.openai.com/v1"
      model: "gpt-4o-mini"
      temperature: 0.7
      max_tokens: 4000
      streaming: false
      is_reasoning: false  # Whether reasoning responses are supported

    o3-mini:  # OpenAI model configuration
      api_key: ""
      api_base: "https://api.openai.com/v1"
      model: "o3-mini"
      temperature: 0.7
      max_tokens: 4000
      streaming: false
      is_reasoning: false

    gpt-4o:  # OpenAI model configuration
      api_key: ""
      api_base: "https://api.openai.com/v1"
      model: "gpt-4o"
      temperature: 0.7
      max_tokens: 4000
      streaming: false
      is_reasoning: false

    deepseek-v3:  # DeepSeek model configuration
      api_key: ""
      api_base: "https://ark.cn-beijing.volces.com/api/v3"
      model: "deepseek-v3-250324"
      temperature: 0.7
      max_tokens: 4000
      is_reasoning: false

    deepseek-r1:  # DeepSeek reasoning model configuration
      api_key: ""
      api_base: "https://ark.cn-beijing.volces.com/api/v3"
      model: "deepseek-r1-250120"
      temperature: 0.7
      max_tokens: 4000
      is_reasoning: true

    claude-3.7-sonnet:  # Claude 3.7 Sonnet via OpenRouter
      api_key: ""
      api_base: "https://openrouter.ai/api/v1"
      model: "anthropic/claude-3.7-sonnet"
      temperature: 0.7
      max_tokens: 4000
      is_reasoning: true

    gemini-2.5-pro:  # Gemini 2.5 Pro via OpenRouter
      api_key: ""
      api_base: "https://openrouter.ai/api/v1"
      model: "google/gemini-2.5-flash-preview"
      temperature: 0.7
      max_tokens: 4000
      is_reasoning: false

  # Global default settings (overridden by model-specific configs)
  temperature: 0.7
  streaming: false
  verbose: false
  is_reasoning: false

# Data Lake Configuration
webtables_config:
  # source_path will be resolved to the project data directory
  source_path: "datas/source"
  file_types:
    - csv
    - xlsx
    - json
  executor:
    safe_mode: true

# Agent Configuration
agent_config:
  max_attempts: 3
  debug_mode: true
  timeout: 10

  # Specific configurations per agent
  sampler:
    complexity_range: [1, 8]

  intent:
    languages: ["Chinese", "English"]

  coder:
    code_format: "pandas"
    max_attempts: 3

  executor:
    safe_mode: true

  # Workflow configuration
  workflow:
    use_sampler_code: true         # Whether to use code generated by SamplerAgent
    prioritize_instruction: false  # Whether to prioritize natural language instruction
    optimization_enabled: false    # Whether to enable code optimization

# Sampling Configuration
sampler_config:
  complexity_transforms:
    "1": 1
    "2": 2
    "3": 3
    "4": 4
    "5": 5
    "6": 6
    "7": 7
    "8": 8
  default_complexity: 5
  sample_tables_per_run: 2

# Storage Configuration
storage_config:
  # output_path will be resolved to the project output directory
  output_path: "datas/benchmark/"
  format: "json"
  save_intermediate: true

# Logging Configuration
log_config:
  log_level: debug  # Options: debug, info, warning, error, critical
  log_dir: logs
  log_to_file: true
